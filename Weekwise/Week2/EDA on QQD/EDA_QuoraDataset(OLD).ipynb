{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDA_QuoraDataset(OLD).ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import seaborn as sns\n","import pandas as pd\n"],"metadata":{"id":"XNwl4nVu7VlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Y417w4FuhOuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKqqlBPtFl7I"},"outputs":[],"source":["!unzip \"drive/MyDrive/Quora-QnA/quora-question-pairs\" -d \"quora-question-pairs\"\n","!unzip \"quora-question-pairs/train.csv.zip\"\n","!unzip \"quora-question-pairs/test.csv.zip\""]},{"cell_type":"code","source":["df = pd.read_csv(\"train.csv\")"],"metadata":{"id":"0RoLOAubF0ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.iloc[:100]"],"metadata":{"id":"qGA1EsyDYZMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"wxXATUFfKCZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(3)"],"metadata":{"id":"rVq3IVlvGRBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.groupby(\"is_duplicate\")['id'].count().plot.bar()"],"metadata":{"id":"LZhxIUa7F2s4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nearly 37% of the rows provided are for duplicate pair examples\n","\n","---\n","\n"],"metadata":{"id":"VfPOzsa8F8XU"}},{"cell_type":"code","source":["print(\"Total unique questions: \" , (df['qid1'].nunique()+df['qid2'].nunique()))"],"metadata":{"id":"VnMHPgrBF412"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in df['qid1']:\n","  num = int(i)+1"],"metadata":{"id":"8eMv9dEpGUBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in df['qid1']:\n","  num = int(i)+1"],"metadata":{"id":"XC4XYfFHHvAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above 2 cells did not return an error. It means that all the question ids in column are numbers as expected"],"metadata":{"id":"as8W2tV1IcLw"}},{"cell_type":"code","source":["map = {}\n","for i in range(len(df)):\n","  if i%50000 == 0:\n","    print(i)\n","  x = str(df.iloc[i]['qid1'])+str(df.iloc[i]['qid2'])\n","  if (x in map.keys()):\n","    print(x, \" ==> duplicate\")\n","  map[x] = 1"],"metadata":{"id":"TWLY8IL3H44W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No duplicate question pair is present in the dataset"],"metadata":{"id":"W5esfPCYKpgO"}},{"cell_type":"markdown","source":["###### Filling null values in dataset with \":\""],"metadata":{"id":"AxeEmifMEdQ6"}},{"cell_type":"code","source":["nan_rows = df[df.isnull().any(1)]\n","df = df.fillna('')\n","nan_rows = df[df.isnull().any(1)]"],"metadata":{"id":"zIkBeOVqH-w5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Checking for how many question are lss than or equal to 2 words"],"metadata":{"id":"ywhP6L7cDz85"}},{"cell_type":"code","source":["counter = 0\n","ls =[]\n","to_remove_indices = []\n","for i in df['question1']:\n","  i = str(i).split()\n","  if len(i) <= 2:\n","    ls.append(counter)\n","  counter+=1"],"metadata":{"id":"FzUdv5wJHqDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"Jeum7fZCKPku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(ls)-1,-1,-1):\n","  df = df.drop(ls[i])"],"metadata":{"id":"A8OPMJNaJl6w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"FUPqxKymJmgr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["140 rows removed where one of the questions was less than 2 words of length"],"metadata":{"id":"BFaHJX-xKYP7"}},{"cell_type":"markdown","source":["### Basic Feature Extraction"],"metadata":{"id":"yxbIX2GhKaSZ"}},{"cell_type":"markdown","source":["##### Extracting feature: common words and ratio of common words to total words in question"],"metadata":{"id":"j7n5fJhvlQwi"}},{"cell_type":"markdown","source":["We will creae new columns in the table as following:\n","\n","\n","> 1. w_q1: number of words in q1\n","> 2. w_q2: number of words in q2\n","> 3. w_common: number of common words in q1 and q2\n","> 4. ratio_q1 = w_common/w_q1\n","> 5. ratio_q1 = w_common/w_q2\n","\n","\n"],"metadata":{"id":"yo4_RYGsKnAM"}},{"cell_type":"code","source":["ls1 = df['question1']\n","ls2 = df['question2']"],"metadata":{"id":"47ypneIZT2TY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"FeCHwWHFT2O_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_q1 = []\n","tokenized_q2 = []"],"metadata":{"id":"ED54K2QiREGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for q in ls1:\n","  tokenized_q1.append(nlp(q))\n","for q in ls2:\n","  tokenized_q2.append(nlp(q))"],"metadata":{"id":"6cPrnvMlX55_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['w_q1'] = pd.Series(tokenized_q1).apply(lambda ar :len(ar))\n","df['w_q2'] = pd.Series(tokenized_q2).apply(lambda ar :len(ar))"],"metadata":{"id":"CCbcZGLUXA4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["common_words = []\n","for i in range(len(df)):\n","  map = {}\n","  count= 0\n","  for token in tokenized_q1[i]:\n","    map[token.text] = True\n","  for token in tokenized_q2[i]:\n","    if token.text in map.keys():\n","      count+=1\n","  common_words.append(count)\n","\n","df['w_comm'] = common_words"],"metadata":{"id":"AncFD91VU2Ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['ratio_q1'] = df['w_comm']/df['w_q1']\n","df['ratio_q2'] = df['w_comm']/df['w_q2']\n","df['jacc'] = df['w_comm']/(df['w_q1']+df['w_q2'])"],"metadata":{"id":"tlYinealeyIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"ekpFiFGcgiYK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[79]"],"metadata":{"id":"PaXrvJrEka4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp1 = df[df['ratio_q1'] > 1]['id']\n","temp2 = df[df['ratio_q1'] > 1]['id']\n","temp3 = []\n","for i in temp1:\n","  temp3.append(i)\n","for i in temp2:\n","  temp3.append(i)\n","temp3.sort()\n","for i in range(len(temp3)-1,0,-1):\n","  try:\n","    df = df.drop(temp3[i])\n","  except:\n","    ;\n","del temp1, temp2, temp3"],"metadata":{"id":"4pkstVRViMEF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sns.displot(df[df['is_duplicate'] == 1]['ratio_q1'], bins = 20)\n","sns.displot(df[df['is_duplicate'] == 1]['jacc'], bins = 20)"],"metadata":{"id":"i2OV_ZPnhB7Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Majority of the questions have 80% of the words same. \n","An unexpected spike at 50% is also observed."],"metadata":{"id":"WP8XKD6AlMET"}},{"cell_type":"markdown","source":["##### Taking a look at a feature :"],"metadata":{"id":"G1N3FNC1lXyM"}},{"cell_type":"code","source":["# plot graph to check ratio only for the smaller(larger) question in size"],"metadata":{"id":"dRF21uzilcPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1. Unigram distribution comput counts \n","2. Try to compute KL divergence for questions\n","3. do sample analysis"],"metadata":{"id":"ngRijO9o-U0P"},"execution_count":null,"outputs":[]}]}