{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SSMBA_QQD.ipynb","provenance":[{"file_id":"1JqzyUugIsCpgF4gXuW0qZ3Tx3qWKmwB7","timestamp":1655583131423}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hnAfr3xe0c7y","executionInfo":{"status":"ok","timestamp":1655585249549,"user_tz":-60,"elapsed":4037,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["!pip --quiet install transformers sentence_transformers"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeEG-Y6m0mud","executionInfo":{"status":"ok","timestamp":1655585252937,"user_tz":-60,"elapsed":3393,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","import numpy as np\n","import torch\n","import requests\n","import json\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer, util"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PEk19thdl6A","executionInfo":{"status":"ok","timestamp":1655585255968,"user_tz":-60,"elapsed":3039,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"9d361c72-700e-404e-8087-8ad1558a6368"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"oGHrxAVaEp4e","executionInfo":{"status":"ok","timestamp":1655585255969,"user_tz":-60,"elapsed":7,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["# input_path = \"/content/drive/MyDrive/val_samples_em.csv\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Il03bLM1HaUo","executionInfo":{"status":"ok","timestamp":1655585255969,"user_tz":-60,"elapsed":6,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["# aqua_df = pd.read_csv(input_path)\n","# questions = aqua_df[\"question\"].tolist()\n","# print(aqua_df.shape)\n","# aqua_df.head()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_X1C1i-Fvr3r","executionInfo":{"status":"ok","timestamp":1655585255969,"user_tz":-60,"elapsed":6,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["def hf_masked_encode(\n","        tokenizer,\n","        sentence: str,\n","        *addl_sentences,\n","        noise_prob=0.0,\n","        random_token_prob=0.0,\n","        leave_unmasked_prob=0.0):\n","\n","    if random_token_prob > 0.0:\n","        weights = np.ones(len(tokenizer.vocab))\n","        weights[tokenizer.all_special_ids] = 0\n","        for k, v in tokenizer.vocab.items():\n","            if '[unused' in k:\n","                weights[v] = 0\n","        weights = weights / weights.sum()\n","\n","    tokens = np.asarray(tokenizer.encode(sentence, *addl_sentences, add_special_tokens=True))\n","\n","    if noise_prob == 0.0:\n","        return tokens\n","\n","    sz = len(tokens)\n","    mask = np.full(sz, False)\n","    num_mask = int(noise_prob * sz + np.random.rand())\n","\n","    mask_choice_p = np.ones(sz)\n","    for i in range(sz):\n","        if tokens[i] in [tokenizer.sep_token_id, tokenizer.cls_token_id, tokenizer.pad_token_id]:\n","            mask_choice_p[i] = 0\n","    mask_choice_p = mask_choice_p / mask_choice_p.sum()\n","\n","    mask[np.random.choice(sz, num_mask, replace=False, p=mask_choice_p)] = True\n","\n","    # decide unmasking and random replacement\n","    rand_or_unmask_prob = random_token_prob + leave_unmasked_prob\n","    if rand_or_unmask_prob > 0.0:\n","        rand_or_unmask = mask & (np.random.rand(sz) < rand_or_unmask_prob)\n","        if random_token_prob == 0.0:\n","            unmask = rand_or_unmask\n","            rand_mask = None\n","        elif leave_unmasked_prob == 0.0:\n","            unmask = None\n","            rand_mask = rand_or_unmask\n","        else:\n","            unmask_prob = leave_unmasked_prob / rand_or_unmask_prob\n","            decision = np.random.rand(sz) < unmask_prob\n","            unmask = rand_or_unmask & decision\n","            rand_mask = rand_or_unmask & (~decision)\n","    else:\n","        unmask = rand_mask = None\n","\n","    if unmask is not None:\n","        mask = mask ^ unmask\n","\n","    tokens[mask] = tokenizer.mask_token_id\n","    if rand_mask is not None:\n","        num_rand = rand_mask.sum()\n","        if num_rand > 0:\n","            tokens[rand_mask] = np.random.choice(\n","                len(tokenizer.vocab),\n","                num_rand,\n","                p=weights,\n","            )\n","\n","    mask_targets = np.full(len(mask), tokenizer.pad_token_id)\n","    mask_targets[mask] = tokens[mask == 1]\n","\n","    return torch.tensor(tokens).long(), torch.tensor(mask_targets).long()\n","\n","def hf_reconstruction_prob_tok(masked_tokens, target_tokens, tokenizer, model, softmax_mask, reconstruct=False, topk=1):\n","    single = False\n","\n","    # expand batch size 1\n","    if masked_tokens.dim() == 1:\n","        single = True\n","        masked_tokens = masked_tokens.unsqueeze(0)\n","        target_tokens = target_tokens.unsqueeze(0)\n","\n","    masked_fill = torch.ones_like(masked_tokens)\n","\n","    masked_index = (target_tokens != tokenizer.pad_token_id).nonzero(as_tuple=True)\n","    masked_orig_index = target_tokens[masked_index]\n","\n","    # edge case of no masked tokens\n","    if len(masked_orig_index) == 0:\n","        if reconstruct:\n","            return masked_tokens, masked_fill\n","        else:\n","            return 1.0\n","\n","    masked_orig_enum = [list(range(len(masked_orig_index))), masked_orig_index]\n","\n","    outputs = model(\n","        masked_tokens.long().to(device=next(model.parameters()).device),\n","        labels=target_tokens\n","    )\n","\n","    features = outputs[1]\n","\n","    logits = features[masked_index].detach().clone()\n","    for l in logits:\n","        l[softmax_mask] = float('-inf')\n","    probs = logits.softmax(dim=-1)\n","\n","\n","    if (reconstruct):\n","\n","        # sample from topk\n","        if topk != -1:\n","            values, indices = probs.topk(k=topk, dim=-1)\n","            kprobs = values.softmax(dim=-1)\n","            if (len(masked_index) > 1):\n","                samples = torch.cat([idx[torch.multinomial(kprob, 1)] for kprob, idx in zip(kprobs, indices)])\n","            else:\n","                samples = indices[torch.multinomial(kprobs, 1)]\n","\n","        # unrestricted sampling\n","        else:\n","            if (len(masked_index) > 1):\n","                samples = torch.cat([torch.multinomial(prob, 1) for prob in probs])\n","            else:\n","                samples = torch.multinomial(probs, 1)\n","\n","        # set samples\n","        masked_tokens[masked_index] = samples\n","        masked_fill[masked_index] = samples\n","\n","        if single:\n","            return masked_tokens[0], masked_fill[0]\n","        else:\n","            return masked_tokens, masked_fill\n","\n","    return torch.sum(torch.log(probs[masked_orig_enum])).item()\n","\n","def fill_batch(batch, min_len, max_len,\n","               tokenizer,\n","               sents,\n","               l,\n","               lines,\n","               labels,\n","               next_sent,\n","               num_gen,\n","               num_tries,\n","               gen_index):\n","\n","    # load sentences into batch until full\n","    while(len(sents) < batch):\n","\n","        # search for the next valid sentence\n","        while True:\n","            if next_sent >= len(lines[0]):\n","                break\n","\n","            next_sents = [s_list[next_sent][0] for s_list in lines]\n","            next_len = len(tokenizer.encode(*next_sents))\n","\n","            # skip input if too short or long\n","            if next_len > min_len and next_len < max_len:\n","                break\n","            next_sent += 1\n","\n","        # add it to our lists\n","        if next_sent < len(lines[0]):\n","            next_sent_lists = [s_list[next_sent] for s_list in lines]\n","            sents.append(list(zip(*next_sent_lists)))\n","            l.append(labels[next_sent])\n","\n","            num_gen.append(0)\n","            num_tries.append(0)\n","            gen_index.append(0)\n","            next_sent += 1\n","        else:\n","            break\n","\n","    return sents, l, next_sent, num_gen, num_tries, gen_index"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"DavJYDchb_-L","executionInfo":{"status":"ok","timestamp":1655585255969,"user_tz":-60,"elapsed":5,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["class SSMBA:\n","    def __init__(self, model_path=\"bert-base-uncased\", seed=1212):\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","        self.r_model = AutoModelWithLMHead.from_pretrained(model_path)\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n","        self.r_model.eval()\n","        if torch.cuda.is_available():\n","            self.r_model.cuda()\n","        self.sem_model = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n","\n","\n","    def augment(self, questions, num_samples=8, noise_prob=0.25, topk=10, shard=0, num_shards=1, batch=8, min_len=4, max_len=512, max_tries=10,\n","                     random_token_prob=0.1, leave_unmasked_prob=0.1, threshold=0.8):\n","\n","        # remove unused vocab and special ids from sampling\n","        questions = questions[::-1]\n","        softmax_mask = np.full(len(self.tokenizer.vocab), False)\n","        softmax_mask[self.tokenizer.all_special_ids] = True\n","        for k, v in self.tokenizer.vocab.items():\n","            if '[unused' in k:\n","                softmax_mask[v] = True\n","\n","        # load the inputs and labels\n","        lines = [tuple(s.strip().split('\\t')) for s in questions]\n","        num_lines = len(lines)\n","        lines = [[[s] for s in s_list] for s_list in list(zip(*lines))]\n","\n","        labels = [0] * num_lines\n","        output_labels = False\n","\n","        # shard the input and labels\n","        if num_shards > 0:\n","            shard_start = (int(num_lines/num_shards) + 1) * shard\n","            shard_end = (int(num_lines/num_shards) + 1) * (shard + 1)\n","            lines = [s_list[shard_start:shard_end] for s_list in lines]\n","            labels = labels[shard_start:shard_end]\n","\n","        s_rec_file = []\n","\n","        # sentences and labels to process\n","        sents = []\n","        l = []\n","\n","        # number sentences generated\n","        num_gen = []\n","\n","        # sentence index to noise from\n","        gen_index = []\n","\n","        # number of tries generating a new sentence\n","        num_tries = []\n","\n","        # next sentence index to draw from\n","        next_sent = 0\n","\n","        sents, l, next_sent, num_gen, num_tries, gen_index = \\\n","                fill_batch(batch, min_len, max_len,\n","                        self.tokenizer,\n","                        sents,\n","                        l,\n","                        lines,\n","                        labels,\n","                        next_sent,\n","                        num_gen,\n","                        num_tries,\n","                        gen_index)\n","\n","        # main augmentation loop\n","        while (sents != []):\n","\n","            # remove any sentences that are done generating and dump to file\n","            for i in range(len(num_gen))[::-1]:\n","                if num_gen[i] == num_samples or num_tries[i] > max_tries:\n","\n","                    # get sent info\n","                    gen_sents = sents.pop(i)\n","                    num_gen.pop(i)\n","                    gen_index.pop(i)\n","                    label = l.pop(i)\n","\n","                    current_sent = []\n","                    original_sent = gen_sents[0]\n","                    original_embedding = self.sem_model.encode(original_sent, convert_to_tensor=True)\n","\n","                    for sg in gen_sents[1:]:\n","                        # s_rec_file.write('\\t'.join([repr(val)[1:-1] for val in sg]) + '\\n')\n","                        current_sent.append(sg[0])\n","\n","                    processed_embeddings = self.sem_model.encode(current_sent, convert_to_tensor=True)\n","                    cosine_scores = util.pytorch_cos_sim(original_embedding, processed_embeddings)\n","                    scores = list(cosine_scores[0])\n","                    current_labels = list(map(lambda x: 1 if x > threshold else 0, scores))\n","                    s_rec_file.append(list(zip(current_sent, current_labels)))\n","\n","            # fill batch\n","            sents, l, next_sent, num_gen, num_tries, gen_index = \\\n","                    fill_batch(batch, min_len, max_len,\n","                            self.tokenizer,\n","                            sents,\n","                            l,\n","                            lines,\n","                            labels,\n","                            next_sent,\n","                            num_gen,\n","                            num_tries,\n","                            gen_index)\n","\n","            # break if done dumping\n","            if len(sents) == 0:\n","                break\n","\n","            # build batch\n","            toks = []\n","            masks = []\n","\n","            for i in range(len(gen_index)):\n","                s = sents[i][gen_index[i]]\n","                tok, mask = hf_masked_encode(\n","                        self.tokenizer,\n","                        *s,\n","                        noise_prob=noise_prob,\n","                        random_token_prob=random_token_prob,\n","                        leave_unmasked_prob=leave_unmasked_prob,\n","                )\n","                toks.append(tok)\n","                masks.append(mask)\n","\n","            # pad up to max len input\n","            max_len = max([len(tok) for tok in toks])\n","            pad_tok = self.tokenizer.pad_token_id\n","\n","            toks = [F.pad(tok, (0, max_len - len(tok)), 'constant', pad_tok) for tok in toks]\n","            masks = [F.pad(mask, (0, max_len - len(mask)), 'constant', pad_tok) for mask in masks]\n","            toks = torch.stack(toks)\n","            masks = torch.stack(masks)\n","\n","            # load to GPU if available\n","            if torch.cuda.is_available():\n","                toks = toks.cuda()\n","                masks = masks.cuda()\n","\n","            # predict reconstruction\n","            rec, rec_masks = hf_reconstruction_prob_tok(toks, masks, self.tokenizer, self.r_model, softmax_mask, reconstruct=True, topk=topk)\n","\n","            # decode reconstructions and append to lists\n","            for i in range(len(rec)):\n","                rec_work = rec[i].cpu().tolist()\n","                s_rec = [s.strip() for s in self.tokenizer.decode([val for val in rec_work if val != self.tokenizer.pad_token_id][1:-1]).split(self.tokenizer.sep_token)]\n","                s_rec = tuple(s_rec)\n","\n","                # check if identical reconstruction or empty\n","                if s_rec not in sents[i] and '' not in s_rec:\n","                    sents[i].append(s_rec)\n","                    num_gen[i] += 1\n","                    num_tries[i] = 0\n","                    gen_index[i] = 0\n","\n","                # otherwise try next sentence\n","                else:\n","                    num_tries[i] += 1\n","                    gen_index[i] += 1\n","                    if gen_index[i] == len(sents[i]):\n","                        gen_index[i] = 0\n","\n","            # clean up tensors\n","            del toks\n","            del masks\n","\n","        return s_rec_file\n","        "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59NckKype01n","executionInfo":{"status":"ok","timestamp":1655585288119,"user_tz":-60,"elapsed":32155,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"4c3c6359-521a-4b52-efe6-a1a647af0f09"},"source":["ssmba = SSMBA()\n","\n","# ssmba.augment(questions[:16], num_samples=8, threshold=0.8)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["qqd = pd.read_csv(\"drive/My Drive/Literature Review/Dataset versions/QQD-cleaner-less.csv\")"],"metadata":{"id":"CukwKj3HeTwn","executionInfo":{"status":"ok","timestamp":1655585289291,"user_tz":-60,"elapsed":1179,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["qqd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"Y-GYueQye7Qd","executionInfo":{"status":"ok","timestamp":1655585289292,"user_tz":-60,"elapsed":30,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"65b9bce8-3421-42d1-af25-cb6e59051c17"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Unnamed: 0      id    qid1    qid2  \\\n","0                0       0       1       2   \n","1                1       1       3       4   \n","2                2       2       5       6   \n","3                3       3       7       8   \n","4                4       4       9      10   \n","...            ...     ...     ...     ...   \n","404213      404285  404285  433578  379845   \n","404214      404286  404286   18840  155606   \n","404215      404287  404287  537928  537929   \n","404216      404288  404288  537930  537931   \n","404217      404289  404289  537932  537933   \n","\n","                                                question1  \\\n","0       what is step by step guide to invest in share ...   \n","1            what is story of kohinoor koh i noor diamond   \n","2       how can i increase speed of my internet connec...   \n","3        why am i mentally very lonely how can i solve it   \n","4       one dissolve in water quickly sugar salt metha...   \n","...                                                   ...   \n","404213  how many keywords are there in racket programm...   \n","404214           do you believe there is life after death   \n","404215                                   what is one coin   \n","404216  what is approx annual cost of living while stu...   \n","404217               what is like to have sex with cousin   \n","\n","                                                question2  is_duplicate  len1  \\\n","0       what is step by step guide to invest in share ...             0    66   \n","1       what would happen if Indian government stole k...             0    51   \n","2       how can internet speed be increased by hacking...             0    73   \n","3       find remainder when math 23 24 math is divided...             0    50   \n","4                        fish would survive in salt water             0    76   \n","...                                                   ...           ...   ...   \n","404213  how many keywords are there in perl programmin...             0    85   \n","404214          is it true that there is life after death             1    41   \n","404215                                   what s this coin             0    17   \n","404216  i am having little hairfall problem but i want...             0    94   \n","404217       what is it like to have sex with your cousin             0    37   \n","\n","        len2  \n","0         57  \n","1         88  \n","2         59  \n","3         65  \n","4         39  \n","...      ...  \n","404213    79  \n","404214    42  \n","404215    17  \n","404216   127  \n","404217    45  \n","\n","[404218 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-d19bbeab-d2a5-482b-af9d-3f67e7477a83\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>len1</th>\n","      <th>len2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is step by step guide to invest in share ...</td>\n","      <td>what is step by step guide to invest in share ...</td>\n","      <td>0</td>\n","      <td>66</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is story of kohinoor koh i noor diamond</td>\n","      <td>what would happen if Indian government stole k...</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase speed of my internet connec...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>73</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely how can i solve it</td>\n","      <td>find remainder when math 23 24 math is divided...</td>\n","      <td>0</td>\n","      <td>50</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>one dissolve in water quickly sugar salt metha...</td>\n","      <td>fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>76</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>404213</th>\n","      <td>404285</td>\n","      <td>404285</td>\n","      <td>433578</td>\n","      <td>379845</td>\n","      <td>how many keywords are there in racket programm...</td>\n","      <td>how many keywords are there in perl programmin...</td>\n","      <td>0</td>\n","      <td>85</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>404214</th>\n","      <td>404286</td>\n","      <td>404286</td>\n","      <td>18840</td>\n","      <td>155606</td>\n","      <td>do you believe there is life after death</td>\n","      <td>is it true that there is life after death</td>\n","      <td>1</td>\n","      <td>41</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>404215</th>\n","      <td>404287</td>\n","      <td>404287</td>\n","      <td>537928</td>\n","      <td>537929</td>\n","      <td>what is one coin</td>\n","      <td>what s this coin</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>404216</th>\n","      <td>404288</td>\n","      <td>404288</td>\n","      <td>537930</td>\n","      <td>537931</td>\n","      <td>what is approx annual cost of living while stu...</td>\n","      <td>i am having little hairfall problem but i want...</td>\n","      <td>0</td>\n","      <td>94</td>\n","      <td>127</td>\n","    </tr>\n","    <tr>\n","      <th>404217</th>\n","      <td>404289</td>\n","      <td>404289</td>\n","      <td>537932</td>\n","      <td>537933</td>\n","      <td>what is like to have sex with cousin</td>\n","      <td>what is it like to have sex with your cousin</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>404218 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d19bbeab-d2a5-482b-af9d-3f67e7477a83')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d19bbeab-d2a5-482b-af9d-3f67e7477a83 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d19bbeab-d2a5-482b-af9d-3f67e7477a83');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["ls = list(qqd['question1'])\n","ls.extend(list(qqd['question2']))"],"metadata":{"id":"MaZYHU_ge0hc","executionInfo":{"status":"ok","timestamp":1655585289292,"user_tz":-60,"elapsed":26,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["len(ls)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfh4YT4Pfl4B","executionInfo":{"status":"ok","timestamp":1655585289292,"user_tz":-60,"elapsed":26,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"4cdacc05-6f6a-4b73-cc9b-4c8feae68892"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["808436"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["df = pd.DataFrame(ls, columns = ['question'])"],"metadata":{"id":"R-oPdOQPesNb","executionInfo":{"status":"ok","timestamp":1655585289293,"user_tz":-60,"elapsed":20,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df = df[:1000]\n","questions = df['question'].tolist()"],"metadata":{"id":"CgJ8ODh-f0Bw","executionInfo":{"status":"ok","timestamp":1655585289293,"user_tz":-60,"elapsed":19,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(df.shape)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"id":"-1ve5iawfSGr","executionInfo":{"status":"ok","timestamp":1655585289293,"user_tz":-60,"elapsed":18,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"4481dacb-ac85-4e13-82e4-0d8491b54cc0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            question\n","0  what is step by step guide to invest in share ...\n","1       what is story of kohinoor koh i noor diamond\n","2  how can i increase speed of my internet connec...\n","3   why am i mentally very lonely how can i solve it\n","4  one dissolve in water quickly sugar salt metha..."],"text/html":["\n","  <div id=\"df-32920a87-6daf-4a2b-bc95-3d4560a09baa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what is step by step guide to invest in share ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>what is story of kohinoor koh i noor diamond</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>how can i increase speed of my internet connec...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>why am i mentally very lonely how can i solve it</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>one dissolve in water quickly sugar salt metha...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32920a87-6daf-4a2b-bc95-3d4560a09baa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-32920a87-6daf-4a2b-bc95-3d4560a09baa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-32920a87-6daf-4a2b-bc95-3d4560a09baa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"93QUCCUheTTo","executionInfo":{"status":"ok","timestamp":1655585289293,"user_tz":-60,"elapsed":12,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}},"outputId":"c1e57e23-98f3-47ce-eadc-ff978bf8ec0c"},"source":["train_set = df.copy().loc[:, ['question']]\n","aug_cols = [f\"aug_{i}\" for i in range(1, 9)];\n","label_cols = [f\"aug_label_{i}\" for i in range(1, 9)]\n","train_set.loc[:, aug_cols] = \"\"\n","train_set.loc[:, label_cols] = \"\"\n","print(train_set.shape)\n","train_set.head()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 17)\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            question aug_1 aug_2 aug_3 aug_4  \\\n","0  what is step by step guide to invest in share ...                           \n","1       what is story of kohinoor koh i noor diamond                           \n","2  how can i increase speed of my internet connec...                           \n","3   why am i mentally very lonely how can i solve it                           \n","4  one dissolve in water quickly sugar salt metha...                           \n","\n","  aug_5 aug_6 aug_7 aug_8 aug_label_1 aug_label_2 aug_label_3 aug_label_4  \\\n","0                                                                           \n","1                                                                           \n","2                                                                           \n","3                                                                           \n","4                                                                           \n","\n","  aug_label_5 aug_label_6 aug_label_7 aug_label_8  \n","0                                                  \n","1                                                  \n","2                                                  \n","3                                                  \n","4                                                  "],"text/html":["\n","  <div id=\"df-e5a35740-cc8a-4366-a5f9-93fed9d5dd03\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>aug_1</th>\n","      <th>aug_2</th>\n","      <th>aug_3</th>\n","      <th>aug_4</th>\n","      <th>aug_5</th>\n","      <th>aug_6</th>\n","      <th>aug_7</th>\n","      <th>aug_8</th>\n","      <th>aug_label_1</th>\n","      <th>aug_label_2</th>\n","      <th>aug_label_3</th>\n","      <th>aug_label_4</th>\n","      <th>aug_label_5</th>\n","      <th>aug_label_6</th>\n","      <th>aug_label_7</th>\n","      <th>aug_label_8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what is step by step guide to invest in share ...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>what is story of kohinoor koh i noor diamond</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>how can i increase speed of my internet connec...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>why am i mentally very lonely how can i solve it</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>one dissolve in water quickly sugar salt metha...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5a35740-cc8a-4366-a5f9-93fed9d5dd03')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e5a35740-cc8a-4366-a5f9-93fed9d5dd03 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e5a35740-cc8a-4366-a5f9-93fed9d5dd03');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"7bwzTkpRwh19","executionInfo":{"status":"ok","timestamp":1655585289293,"user_tz":-60,"elapsed":7,"user":{"displayName":"Maksimjeet Chowdhary","userId":"13101293791869032855"}}},"source":["output_path = \"EM_SSMBA_val.csv\""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhkrVAqkiP7j","outputId":"3df6b6cd-bc2d-4f68-b62f-d3fb45a5726f"},"source":["start = train_set[train_set[\"aug_1\"]==\"\"].index[0]\n","print(f\"[INFO] Starting from {start}.\")\n","for i in range(start, len(questions), 8):\n","    questions_ = questions[i: i+8]\n","    generated = ssmba.augment(questions_, num_samples=8, threshold=0.8)\n","    print(f\"[INFO] {i+1}:{i+8} questions generated.\")\n","    for idx, gen in enumerate(generated):\n","        augs, labels = list(zip(*gen))\n","        train_set.loc[i+idx, aug_cols+label_cols] = augs+labels\n","    train_set.to_csv(output_path, index=False)\n","train_set.to_csv(output_path, index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Starting from 0.\n","[INFO] 1:8 questions generated.\n","[INFO] 9:16 questions generated.\n","[INFO] 17:24 questions generated.\n","[INFO] 25:32 questions generated.\n","[INFO] 33:40 questions generated.\n","[INFO] 41:48 questions generated.\n","[INFO] 49:56 questions generated.\n","[INFO] 57:64 questions generated.\n","[INFO] 65:72 questions generated.\n","[INFO] 73:80 questions generated.\n","[INFO] 81:88 questions generated.\n","[INFO] 89:96 questions generated.\n","[INFO] 97:104 questions generated.\n","[INFO] 105:112 questions generated.\n","[INFO] 113:120 questions generated.\n","[INFO] 121:128 questions generated.\n","[INFO] 129:136 questions generated.\n","[INFO] 137:144 questions generated.\n","[INFO] 145:152 questions generated.\n","[INFO] 153:160 questions generated.\n","[INFO] 161:168 questions generated.\n","[INFO] 169:176 questions generated.\n","[INFO] 177:184 questions generated.\n","[INFO] 185:192 questions generated.\n","[INFO] 193:200 questions generated.\n","[INFO] 201:208 questions generated.\n","[INFO] 209:216 questions generated.\n","[INFO] 217:224 questions generated.\n","[INFO] 225:232 questions generated.\n","[INFO] 233:240 questions generated.\n","[INFO] 241:248 questions generated.\n","[INFO] 249:256 questions generated.\n","[INFO] 257:264 questions generated.\n","[INFO] 265:272 questions generated.\n","[INFO] 273:280 questions generated.\n","[INFO] 281:288 questions generated.\n","[INFO] 289:296 questions generated.\n","[INFO] 297:304 questions generated.\n","[INFO] 305:312 questions generated.\n","[INFO] 313:320 questions generated.\n","[INFO] 321:328 questions generated.\n","[INFO] 329:336 questions generated.\n","[INFO] 337:344 questions generated.\n","[INFO] 345:352 questions generated.\n","[INFO] 353:360 questions generated.\n","[INFO] 361:368 questions generated.\n","[INFO] 369:376 questions generated.\n","[INFO] 377:384 questions generated.\n","[INFO] 385:392 questions generated.\n","[INFO] 393:400 questions generated.\n","[INFO] 401:408 questions generated.\n","[INFO] 409:416 questions generated.\n","[INFO] 417:424 questions generated.\n","[INFO] 425:432 questions generated.\n","[INFO] 433:440 questions generated.\n","[INFO] 441:448 questions generated.\n","[INFO] 449:456 questions generated.\n","[INFO] 457:464 questions generated.\n","[INFO] 465:472 questions generated.\n","[INFO] 473:480 questions generated.\n","[INFO] 481:488 questions generated.\n","[INFO] 489:496 questions generated.\n","[INFO] 497:504 questions generated.\n","[INFO] 505:512 questions generated.\n","[INFO] 513:520 questions generated.\n","[INFO] 521:528 questions generated.\n","[INFO] 529:536 questions generated.\n","[INFO] 537:544 questions generated.\n","[INFO] 545:552 questions generated.\n","[INFO] 553:560 questions generated.\n","[INFO] 561:568 questions generated.\n","[INFO] 569:576 questions generated.\n","[INFO] 577:584 questions generated.\n","[INFO] 585:592 questions generated.\n","[INFO] 593:600 questions generated.\n","[INFO] 601:608 questions generated.\n","[INFO] 609:616 questions generated.\n","[INFO] 617:624 questions generated.\n","[INFO] 625:632 questions generated.\n","[INFO] 633:640 questions generated.\n","[INFO] 641:648 questions generated.\n","[INFO] 649:656 questions generated.\n","[INFO] 657:664 questions generated.\n","[INFO] 665:672 questions generated.\n","[INFO] 673:680 questions generated.\n","[INFO] 681:688 questions generated.\n","[INFO] 689:696 questions generated.\n","[INFO] 697:704 questions generated.\n","[INFO] 705:712 questions generated.\n","[INFO] 713:720 questions generated.\n","[INFO] 721:728 questions generated.\n","[INFO] 729:736 questions generated.\n","[INFO] 737:744 questions generated.\n","[INFO] 745:752 questions generated.\n","[INFO] 753:760 questions generated.\n","[INFO] 761:768 questions generated.\n","[INFO] 769:776 questions generated.\n","[INFO] 777:784 questions generated.\n","[INFO] 785:792 questions generated.\n","[INFO] 793:800 questions generated.\n","[INFO] 801:808 questions generated.\n","[INFO] 809:816 questions generated.\n","[INFO] 817:824 questions generated.\n","[INFO] 825:832 questions generated.\n","[INFO] 833:840 questions generated.\n","[INFO] 841:848 questions generated.\n","[INFO] 849:856 questions generated.\n","[INFO] 857:864 questions generated.\n","[INFO] 865:872 questions generated.\n","[INFO] 873:880 questions generated.\n","[INFO] 881:888 questions generated.\n","[INFO] 889:896 questions generated.\n","[INFO] 897:904 questions generated.\n","[INFO] 905:912 questions generated.\n","[INFO] 913:920 questions generated.\n","[INFO] 921:928 questions generated.\n","[INFO] 929:936 questions generated.\n","[INFO] 937:944 questions generated.\n","[INFO] 945:952 questions generated.\n","[INFO] 953:960 questions generated.\n"]}]},{"cell_type":"code","metadata":{"id":"iH-HrPugrxvg"},"source":["print(train_set[train_set[\"aug_1\"]==\"\"].index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set.transpose().iloc[:9].transpose()"],"metadata":{"id":"ZkFyrgVxjchI"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"scid7aNhr1H5"},"source":["# idx = 30000\n","# a, l = list(zip(*ssmba.augment([train_set.loc[idx, \"question\"]], num_samples=8, threshold=0.8)[0]))\n","# train_set.loc[idx, aug_cols+label_cols] = a + l\n","# train_set.loc[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whzxCb4vseR7"},"source":["train_set.to_csv(output_path, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmB-fP6pTWX8"},"source":[""],"execution_count":null,"outputs":[]}]}