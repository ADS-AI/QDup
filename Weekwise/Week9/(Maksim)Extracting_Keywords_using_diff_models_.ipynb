{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenkteshV/Question_duplicate_detection/blob/main/Week9/(Maksim)Extracting_Keywords_using_diff_models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ1vYReHI27I",
        "outputId": "0eb12699-7f45-4c1b-81ac-31109b0c4cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 63.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.1 MB/s \n",
            "\u001b[?25h  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet keybert\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caj0ikmt5bsy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import pke\n",
        "from tqdm import tqdm\n",
        "from spacy.matcher import Matcher\n",
        "import time\n",
        "import numpy as np\n",
        "from keybert import KeyBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhmhutB15oMN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8GUVtlC5oei"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Extramarks Project/Dataset versions/Model1-Semantic/Jacc_sim_ignore_syllabus.csv\")\n",
        "df = df.drop(\"Unnamed: 0\", axis= 1)\n",
        "df = df[:100]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8wvRPq35sj4"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-CBLVXbLqmJ"
      },
      "outputs": [],
      "source": [
        "pke_extractors = [\n",
        "                  # pke.unsupervised.TfIdf, \n",
        "                  # pke.unsupervised.YAKE, \n",
        "                  # pke.unsupervised.TextRank,  \n",
        "                  # pke.unsupervised.TopicRank, \n",
        "                  pke.unsupervised.TopicalPageRank, \n",
        "                  pke.unsupervised.PositionRank, \n",
        "                  pke.unsupervised.MultipartiteRank\n",
        "                  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La9RjEnaBWuq"
      },
      "outputs": [],
      "source": [
        "def keyword_model_extractor(ind, text):\n",
        "    extractor = pke_extractors[ind]()\n",
        "    extractor.load_document(text, language='en')\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ', 'ADV'}\n",
        "\n",
        "    # if pke_extractors[ind].__name__ == \"TfIdf\":\n",
        "    #   extractor.candidate_selection(n=3)\n",
        "    if pke_extractors[ind].__name__ == \"KPMiner\":\n",
        "      extractor.candidate_selections()\n",
        "    if pke_extractors[ind].__name__ == \"YAKE\":\n",
        "      extractor.candidate_selection()\n",
        "    elif pke_extractors[ind].__name__ == \"TextRank\":\n",
        "      extractor.candidate_selection(pos = pos)\n",
        "    elif pke_extractors[ind].__name__ == \"TopicRank\":\n",
        "      extractor.candidate_selection(pos = pos)\n",
        "    elif pke_extractors[ind].__name__ == \"TopicalPageRank\":\n",
        "      extractor.candidate_selection()\n",
        "    elif pke_extractors[ind].__name__ == \"PositionRank\":\n",
        "      extractor.candidate_selection()\n",
        "    elif pke_extractors[ind].__name__ == \"MultipartiteRank\":\n",
        "      extractor.candidate_selection(pos = pos)\n",
        "\n",
        "\n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keyphrases:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh0yKnlHI-eR"
      },
      "outputs": [],
      "source": [
        "# for ind in range(len(pke_extractors)):\n",
        "#   print(\"Model name : \"+  pke_extractors[ind].__name__)\n",
        "#   corpus_kws = {}\n",
        "#   try:\n",
        "#     for idx, text in tqdm(enumerate(questions_ls)):\n",
        "#       corpus_kws[idx] = keyword_model_extractor(ind, text)\n",
        "#   except:\n",
        "#     corpus_kws[idx] = []\n",
        "#   corpus_kws_df = pd.DataFrame(pd.Series(corpus_kws), columns=[\"keywords\"])\n",
        "#   pd.concat([df, corpus_kws_df], axis=1).to_csv('/content/drive/MyDrive/Extramarks Project/Week8/'+ pke_extractors[ind].__name__+ '-extracted_keywords.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f5CFm0fg1qZ"
      },
      "outputs": [],
      "source": [
        "def intersection_list(list1, list2):  \n",
        "   list3 = [value for value in list1 if value in list2]  \n",
        "   return list3 \n",
        "\n",
        "def union_list(list1, list2):\n",
        "  set1 = set(list1)\n",
        "  set2 = set(list2)\n",
        "  newList = list(set1.union(set2)) \n",
        "  return newList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExrbQp5bhI9X"
      },
      "outputs": [],
      "source": [
        "def keyword_score(question1, question2, ind):\n",
        "\n",
        "  # print(question1)\n",
        "  # print(question2)\n",
        "\n",
        "  try :\n",
        "    keyword1 = keyword_model_extractor(ind, question1)\n",
        "  except :\n",
        "    keyword1 = []\n",
        "\n",
        "  try :\n",
        "    keyword2 = keyword_model_extractor(ind, question2)\n",
        "  except :\n",
        "    keyword2 = []\n",
        "\n",
        "  common_keyword = intersection_list(keyword1, keyword2)\n",
        "  union_keyword = union_list(keyword1, keyword2)\n",
        "\n",
        "  if(union_keyword == []):      # suggestive model\n",
        "    return 1\n",
        "\n",
        "  return len(common_keyword)/len(union_keyword)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bVqzNjqiJVa"
      },
      "outputs": [],
      "source": [
        "# df = df.reset_index()  # make sure indexes pair with number of rows\n",
        "\n",
        "# 1. Split keywords\n",
        "# 2. Embeddings\n",
        "\n",
        "threshold_val = 0.5\n",
        "score_values = []\n",
        "for index, row in df.iterrows():\n",
        "    if index % 250 == 0:\n",
        "      print(index)\n",
        "    question1 = row['ques1'] \n",
        "    question2 = row['ques2']\n",
        "    score_values.append(keyword_score(question1, question2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-A2Q52cINWV"
      },
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame(df)\n",
        "new_df['keword_score'] = score_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWG9TiOGINRJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZwmK7dfouhu"
      },
      "outputs": [],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOVySUWvA1UN"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('/content/drive/MyDrive/Extramarks Project/Dataset versions/Model2-Keyword/Added_keyword_overlap_score.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da9s3Go3pRyO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "(Maksim)Extracting_Keywords_using_diff_models .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}